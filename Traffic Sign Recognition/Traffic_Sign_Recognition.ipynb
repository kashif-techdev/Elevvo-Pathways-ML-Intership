{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üö¶ Traffic Sign Recognition - Advanced Deep Learning Project\n",
        "\n",
        "## Overview\n",
        "This notebook implements a comprehensive traffic sign recognition system using various deep learning approaches:\n",
        "- **Custom CNN** from scratch\n",
        "- **Transfer Learning** with MobileNetV2, VGG16, and ResNet50\n",
        "- **Data Augmentation** for improved generalization\n",
        "- **Comprehensive Evaluation** with detailed visualizations\n",
        "\n",
        "## Dataset: GTSRB (German Traffic Sign Recognition Benchmark)\n",
        "- 43 different traffic sign classes\n",
        "- High-quality RGB images\n",
        "- Varying resolutions and lighting conditions\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Import Libraries and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep learning libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Sklearn for evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Custom modules\n",
        "from data_preprocessing import TrafficSignDataProcessor\n",
        "from models import TrafficSignModelBuilder\n",
        "from training_evaluation import TrafficSignTrainer\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Data Loading and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize data processor\n",
        "processor = TrafficSignDataProcessor(img_size=(64, 64))\n",
        "\n",
        "# For Google Colab, you'll need to upload the GTSRB dataset\n",
        "# You can download it from: https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n",
        "\n",
        "# Example paths (adjust based on your dataset location)\n",
        "train_csv_path = '/content/Train.csv'  # Path to training CSV\n",
        "train_images_path = '/content/Train'   # Path to training images\n",
        "test_csv_path = '/content/Test.csv'    # Path to test CSV\n",
        "test_images_path = '/content/Test'    # Path to test images\n",
        "\n",
        "print(\"üìÅ Dataset paths configured\")\n",
        "print(f\"Training CSV: {train_csv_path}\")\n",
        "print(f\"Training Images: {train_images_path}\")\n",
        "print(f\"Test CSV: {test_csv_path}\")\n",
        "print(f\"Test Images: {test_images_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training data\n",
        "print(\"üîÑ Loading training data...\")\n",
        "X_train_full, y_train_full = processor.load_data_from_csv(train_csv_path, train_images_path)\n",
        "\n",
        "# Load test data\n",
        "print(\"üîÑ Loading test data...\")\n",
        "X_test, y_test = processor.load_data_from_csv(test_csv_path, test_images_path)\n",
        "\n",
        "print(f\"‚úÖ Training data loaded: {X_train_full.shape}\")\n",
        "print(f\"‚úÖ Test data loaded: {X_test.shape}\")\n",
        "print(f\"‚úÖ Number of classes: {len(np.unique(y_train_full))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split training data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = processor.split_data(\n",
        "    X_train_full, y_train_full, \n",
        "    test_size=0.2, val_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Encode labels to categorical format\n",
        "y_train_encoded, y_val_encoded, y_test_encoded = processor.encode_labels(\n",
        "    y_train, y_val, y_test\n",
        ")\n",
        "\n",
        "print(f\"üìä Data split completed:\")\n",
        "print(f\"  Training: {X_train.shape[0]} samples\")\n",
        "print(f\"  Validation: {X_val.shape[0]} samples\")\n",
        "print(f\"  Test: {X_test.shape[0]} samples\")\n",
        "print(f\"  Image shape: {X_train.shape[1:]}\")\n",
        "print(f\"  Number of classes: {y_train_encoded.shape[1]}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
